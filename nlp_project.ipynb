{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for NLP - Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RULES:\n",
    "\n",
    "* Do not create any additional cell\n",
    "\n",
    "* Fill in the blanks\n",
    "\n",
    "* All cells should be runnable (modulo trivial compatibility bugs that we'd fix)\n",
    "\n",
    "* 4 / 20 points will be allocated to the clarity of your code\n",
    "\n",
    "* Efficient code will have a bonus\n",
    "\n",
    "DELIVERABLE:\n",
    "\n",
    "* the pdf with your answers\n",
    "* this notebook\n",
    "* the predictions of the SST test set\n",
    "\n",
    "DO NOT INCLUDE THE DATASETS IN THE DELIVERABLE.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Python 3.6 or above is required\n",
    "from collections import defaultdict\n",
    "import gzip\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import urllib\n",
    "import tqdm\n",
    "import time\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = Path('data/')\n",
    "# Download word vectors, might take a few minutes and about ~3GB of storage space\n",
    "en_embeddings_path = PATH_TO_DATA / 'cc.en.300.vec.gz'\n",
    "if not en_embeddings_path.exists():\n",
    "    urllib.request.urlretrieve('https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz', en_embeddings_path)\n",
    "fr_embeddings_path = PATH_TO_DATA / 'cc.fr.300.vec.gz'\n",
    "if not fr_embeddings_path.exists():\n",
    "    urllib.request.urlretrieve('https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fr.300.vec.gz', fr_embeddings_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Monolingual (English) word embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec():\n",
    "\n",
    "    def __init__(self, filepath, vocab_size=50000):\n",
    "        self.words, self.embeddings = self.load_wordvec(filepath, vocab_size)\n",
    "        # Mappings for O(1) retrieval:\n",
    "        self.word2id = {word: idx for idx, word in enumerate(self.words)}\n",
    "        self.id2word = {idx: word for idx, word in enumerate(self.words)}\n",
    "    \n",
    "    def load_wordvec(self, filepath, vocab_size):\n",
    "        assert str(filepath).endswith('.gz')\n",
    "        words = []\n",
    "        embeddings = []\n",
    "        with gzip.open(filepath, 'rt') as f:  # Read compressed file directly\n",
    "            next(f)  # Skip header\n",
    "            for i, line in enumerate(f):\n",
    "                word, vec = line.split(' ', 1)\n",
    "                words.append(word)\n",
    "                embeddings.append(np.fromstring(vec, sep=' '))\n",
    "                if i == (vocab_size - 1):\n",
    "                    break\n",
    "        print('Loaded %s pretrained word vectors' % (len(words)))\n",
    "        return words, np.vstack(embeddings)\n",
    "    \n",
    "    def encode(self, word):\n",
    "        # Returns the 1D embedding of a given word\n",
    "        word_id = self.word2id[word]\n",
    "        return self.embeddings[word_id]\n",
    "    \n",
    "    def score(self, word1, word2):\n",
    "        # Return the cosine similarity: use np.dot & np.linalg.norm\n",
    "        word1_embedding = self.encode(word1)\n",
    "        word2_embedding = self.encode(word2)\n",
    "        cosine_dist = 1 - np.dot(word1_embedding,word2_embedding)/(np.linalg.norm(word1_embedding)*np.linalg.norm(word2_embedding))\n",
    "        return cosine_dist\n",
    "    \n",
    "    def most_similar(self, word, k=5):\n",
    "        # Returns the k most similar words: self.score & np.argsort\n",
    "        distances = np.array([self.score(word, other_word) for other_word in self.words])\n",
    "        distances_int = np.argsort(distances)\n",
    "        neighbors = []\n",
    "        for rank in range(k+1):\n",
    "            neighbor_id = distances_int[rank]\n",
    "            neighbor_wrd = self.id2word[neighbor_id]\n",
    "            if (not neighbor_wrd==word) and (len(neighbors)!=k):\n",
    "                # the word itself isn't considered a neighbor\n",
    "                # a situation might occur in which k neighbors embeddings are colinear to the word embedding\n",
    "                # thus, the word itself might not appear at first in the top k neighbors\n",
    "                neighbors.append(neighbor_wrd)\n",
    "        return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50000 pretrained word vectors\n",
      "cat tree 0.7355024533834524\n",
      "cat dog 0.2921358701457436\n",
      "cat pet 0.32466866400236194\n",
      "Paris France 0.31070410741934595\n",
      "Paris Germany 0.5948757713262451\n",
      "Paris baguette 0.7060004172219778\n",
      "Paris donut 1.006588507552348\n",
      "['cats', 'kitty', 'kitten', 'feline', 'dog']\n",
      "['dogs', 'puppy', 'pup', 'canine', 'pet']\n",
      "['dog', 'cats', 'puppies', 'Dogs', 'pets']\n",
      "['France', 'Parisian', 'Marseille', 'Brussels', 'Strasbourg']\n",
      "['Austria', 'Europe', 'Berlin', 'Hamburg', 'Bavaria']\n"
     ]
    }
   ],
   "source": [
    "word2vec = Word2Vec(en_embeddings_path, vocab_size=50000)\n",
    "\n",
    "# You will be evaluated on the output of the following:\n",
    "for word1, word2 in zip(('cat', 'cat', 'cat', 'Paris', 'Paris', 'Paris', 'Paris'), ('tree', 'dog', 'pet', 'France', 'Germany', 'baguette', 'donut')):\n",
    "    print(word1, word2, word2vec.score(word1, word2))\n",
    "for word in ['cat', 'dog', 'dogs', 'Paris', 'Germany']:\n",
    "    print(word2vec.most_similar(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class BagOfWords():\n",
    "    \n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "    \n",
    "    def build_idf(self, sentences):\n",
    "        # build the idf dictionary: associate each word to its idf value\n",
    "        # -> idf = {word: idf_value, ...}\n",
    "        sentences_nb = len(sentences)\n",
    "        idf = {word:0 for word in self.word2vec.words}\n",
    "        for stc in sentences:\n",
    "            stc_wds = stc.split(' ')\n",
    "            stc_wds.remove('')\n",
    "            for word in np.unique(np.array(stc_wds)):\n",
    "                try:\n",
    "                    idf[word]+=1\n",
    "                except:\n",
    "                    pass # because this means that the word isn't in the known words\n",
    "        for word in self.word2vec.words:\n",
    "            try:\n",
    "                idf[word] = np.log(sentences_nb / idf[word]) if idf[word] > 0 else 0\n",
    "            except:\n",
    "                pass # because this means that the word isn't in the known words\n",
    "            \n",
    "        return idf\n",
    "    \n",
    "    def encode(self, sentence, idf=None):\n",
    "        # Takes a sentence as input, returns the sentence embedding\n",
    "        sentence = sentence.split(' ')\n",
    "        try:\n",
    "            sentence.remove('')\n",
    "        except:\n",
    "            pass\n",
    "        embed_sentence = []\n",
    "        for word in sentence: # Here I could save the known encodings in a dictionnary\n",
    "            try:\n",
    "                embed_sentence.append(self.word2vec.encode(word))\n",
    "            except:\n",
    "                pass # because this means that the word isn't in the known words\n",
    "        embed_sentence = np.array(embed_sentence)\n",
    "        \n",
    "        if idf is None:\n",
    "            # mean of word vectors\n",
    "            return np.mean(embed_sentence, axis=0)\n",
    "        else:\n",
    "            # idf-weighted mean of word vectors\n",
    "            sentence_idf = []\n",
    "            for word in sentence:\n",
    "                try:\n",
    "                    sentence_idf.append(idf[word])\n",
    "                except:\n",
    "                    pass # because this means that the word isn't in the known words\n",
    "            sentence_idf = np.array(sentence_idf).reshape(-1,1)\n",
    "            result = np.sum(np.multiply(embed_sentence,sentence_idf),axis=0)/np.sum(sentence_idf) \\\n",
    "                            if np.sum(sentence_idf)!=0 else np.zeros(embed_sentence.shape[1])\n",
    "            return result\n",
    "\n",
    "    def score(self, sentence1, sentence2, idf=None, encoded=False):\n",
    "        # cosine similarity: use np.dot & np.linalg.norm \n",
    "        if not encoded:\n",
    "            sentence1_embedding = self.encode(sentence1, idf)\n",
    "            sentence2_embedding = self.encode(sentence2, idf)\n",
    "        else:\n",
    "            sentence1_embedding, sentence2_embedding = sentence1, sentence2\n",
    "        cosine_dist = 1 - np.dot(sentence1_embedding,sentence2_embedding)/\\\n",
    "                            (np.linalg.norm(sentence1_embedding)*np.linalg.norm(sentence2_embedding))\n",
    "        return cosine_dist\n",
    "    \n",
    "    def most_similar(self, sentence, sentences, idf=None, k=5):\n",
    "        # Return most similar sentences\n",
    "        query = self.encode(sentence, idf)\n",
    "        keys = np.vstack([self.encode(stc, idf) for stc in sentences])\n",
    "        similarities = [self.score(query, other_stc, idf, encoded=True) for other_stc in tqdm.tqdm(keys)]\n",
    "        similarities_int = np.argsort(similarities)\n",
    "        neighbors = []\n",
    "        for rank in range(k+1):\n",
    "            neighbor_id = similarities_int[rank]\n",
    "            neighbor_stc = sentences[neighbor_id]\n",
    "            if (not neighbor_stc==sentence) and (len(neighbors)!=k):\n",
    "                # the sentence itself isn't considered a neighbor\n",
    "                # a situation might occur in which k neighbors embeddings are colinear to the sentence embedding\n",
    "                # thus, the sentence itself might not appear at first in the top k neighbors\n",
    "                neighbors.append(neighbor_stc)\n",
    "        return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50000 pretrained word vectors\n",
      "\n",
      "\tAverage of word embeddings\n",
      "1 man singing and 1 man playing a saxophone in a concert . \n",
      "10 people venture out to go crosscountry skiing . \n",
      "0.29347793517485266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150736/150736 [00:05<00:00, 26402.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 little kids are playing football . \n",
      "1) 3 kids are playing with bubbles outside . \n",
      "2) 4 men are playing dominoes together . \n",
      "3) 2 kids holding hands and smiling . \n",
      "4) 2 hockey teams are playing hockey . \n",
      "5) these four people are standing outdoors , with 3 dogs . \n",
      "\n",
      "\tidf weighted average of word embeddings\n",
      "1 man singing and 1 man playing a saxophone in a concert . \n",
      "10 people venture out to go crosscountry skiing . \n",
      "0.35992000606536156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150736/150736 [00:05<00:00, 27904.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 little kids are playing football . \n",
      "1) 3 kids are playing with bubbles outside . \n",
      "2) five children , 3 boys and 2 girls playing soccer in a grass field . \n",
      "3) 2 kids playing on a seesaw \n",
      "4) a woman walking with 4 kids . \n",
      "5) 5 children , 2 boys and 3 girls , share food while sitting outside of a building . \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "word2vec = Word2Vec(en_embeddings_path, vocab_size=50000)\n",
    "sentence2vec = BagOfWords(word2vec)\n",
    "\n",
    "# Load sentences in \"PATH_TO_DATA/sentences.txt\"\n",
    "filepath = PATH_TO_DATA / 'sentences.txt'\n",
    "with open(filepath, 'r') as f:\n",
    "    sentences = [line.strip('\\n') for line in f]\n",
    "\n",
    "# You will be evaluated on the output of the following:\n",
    "print('\\n\\tAverage of word embeddings')\n",
    "sentence1 = sentences[7] # original : 7\n",
    "sentence2 = sentences[13] # original : 13\n",
    "print(sentence1)\n",
    "print(sentence2)\n",
    "print(sentence2vec.score(sentence1, sentence2))\n",
    "sentence = sentences[300] # original : 10\n",
    "similar_sentences = sentence2vec.most_similar(sentence, sentences)  # BagOfWords-mean\n",
    "print(sentence)\n",
    "for i, sentence_nghbr in enumerate(similar_sentences):\n",
    "    print(str(i+1) + ')', sentence_nghbr)\n",
    "\n",
    "# Build idf scores for each word\n",
    "idf = sentence2vec.build_idf(sentences)\n",
    "\n",
    "print('\\n\\tidf weighted average of word embeddings')\n",
    "print(sentence1)\n",
    "print(sentence2)\n",
    "print(sentence2vec.score(sentence1, sentence2, idf))\n",
    "similar_sentences = sentence2vec.most_similar(sentence, sentences, idf)  # BagOfWords-idf\n",
    "print(sentence)\n",
    "for i, sentence_nghbr in enumerate(similar_sentences):\n",
    "    print(str(i+1) + ')', sentence_nghbr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Multilingual (English-French) word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider a bilingual dictionary of size V_a (e.g French-English).\n",
    "\n",
    "Let's define **X** and **Y** the **French** and **English** matrices.\n",
    "\n",
    "They contain the embeddings associated to the words in the bilingual dictionary.\n",
    "\n",
    "We want to find a **mapping W** that will project the source word space (e.g French) to the target word space (e.g English).\n",
    "\n",
    "Procrustes : **W\\* = argmin || W.X - Y ||  s.t  W^T.W = Id**\n",
    "has a closed form solution:\n",
    "**W = U.V^T  where  U.Sig.V^T = SVD(Y.X^T)**\n",
    "\n",
    "In what follows, you are asked to: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilingualWordAligner:\n",
    "    \n",
    "    def __init__(self, fr_word2vec, en_word2vec):\n",
    "        self.fr_word2vec = fr_word2vec\n",
    "        self.en_word2vec = en_word2vec\n",
    "        self.aligned_fr_embeddings = self.get_aligned_fr_embeddings()\n",
    "        \n",
    "    def get_aligned_fr_embeddings(self):\n",
    "        # 1 - Get words that appear in both vocabs (= identical character strings)\n",
    "        #     Use it to create the matrix X (emb_dim, vocab_size) and Y (emb_dim, vocab_size) \n",
    "        #     (of embeddings for these words)\n",
    "        X = []\n",
    "        Y = []\n",
    "        fr_vocab = set(self.fr_word2vec.words)\n",
    "        en_vocab = set(self.en_word2vec.words)\n",
    "        common_vocab = fr_vocab - (fr_vocab - en_vocab)\n",
    "        \n",
    "        for wrd in common_vocab:\n",
    "            X.append(list(self.fr_word2vec.encode(wrd)))\n",
    "            Y.append(list(self.en_word2vec.encode(wrd)))\n",
    "        \n",
    "        #for fr_word in self.fr_word2vec.words:\n",
    "        #    for en_word in self.en_word2vec.words:\n",
    "        #        \n",
    "        #        if fr_word==en_word:\n",
    "        #            X.append(self.fr_word2vec.encode(fr_word))\n",
    "        #            Y.append(self.en_word2vec.encode(en_word))\n",
    "            \n",
    "        X, Y = np.array(X).transpose(), np.array(Y).transpose()\n",
    "        assert X.shape[0] == 300 and Y.shape[0] == 300\n",
    "        \n",
    "        # 2 - Solve the Procrustes using the numpy package and: np.linalg.svd() and get the optimal W\n",
    "        #     Now self.fr_word2vec.embeddings * W.transpose() is in the same space as en_word2vec.embeddings\n",
    "        u, s, vh = np.linalg.svd(np.matmul(Y, X.transpose()))\n",
    "        W = np.matmul(u, vh)\n",
    "        assert W.shape == (300, 300)\n",
    "        return np.matmul(self.fr_word2vec.embeddings, W.transpose())\n",
    "    \n",
    "    def get_closest_english_words(self, fr_word, k=3):\n",
    "        # 3 - Return the top k English nearest neighbors to the input French word\n",
    "        fr_wrd_id = self.fr_word2vec.word2id[fr_word]\n",
    "        fr2en_wrd_emb = self.aligned_fr_embeddings[fr_wrd_id]\n",
    "        scores = 1 - np.divide(np.dot(fr2en_wrd_emb,self.en_word2vec.embeddings.transpose()),\n",
    "                               np.linalg.norm(fr2en_wrd_emb)*np.linalg.norm(self.en_word2vec.embeddings,axis=1))\n",
    "        scores_int = np.argsort(scores)\n",
    "        neighbors = []\n",
    "        for rank in range(k):\n",
    "            neighbor_id = scores_int[rank]\n",
    "            neighbor_wrd = self.en_word2vec.id2word[neighbor_id]\n",
    "            neighbors.append(neighbor_wrd)\n",
    "            \n",
    "        return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50000 pretrained word vectors\n",
      "Loaded 50000 pretrained word vectors\n",
      "----------\n",
      "fr: \"finance\"\n",
      "en: \"finance\"\n",
      "en: \"banking\"\n",
      "en: \"financial\"\n",
      "en: \"economics\"\n",
      "en: \"education\"\n",
      "en: \"fund\"\n",
      "en: \"capitalism\"\n",
      "en: \"sector\"\n",
      "en: \"financing\"\n",
      "en: \"taxation\"\n",
      "----------\n",
      "fr: \"mission\"\n",
      "en: \"mission\"\n",
      "en: \"missions\"\n",
      "en: \"Mission\"\n",
      "en: \"Missions\"\n",
      "en: \"vocation\"\n",
      "en: \"assignment\"\n",
      "en: \"rescue\"\n",
      "en: \"tasked\"\n",
      "en: \"feasibility\"\n",
      "en: \"responsibilities\"\n",
      "----------\n",
      "fr: \"attention\"\n",
      "en: \"attention\"\n",
      "en: \"regard\"\n",
      "en: \"consideration\"\n",
      "en: \"careful\"\n",
      "en: \"concern\"\n",
      "en: \"exposition\"\n",
      "en: \"mentioning\"\n",
      "en: \"emphasis\"\n",
      "en: \"beware\"\n",
      "en: \"immediate\"\n",
      "----------\n",
      "fr: \"chat\"\n",
      "en: \"cat\"\n",
      "en: \"kitten\"\n",
      "en: \"kitty\"\n",
      "en: \"pet\"\n",
      "en: \"dog\"\n",
      "en: \"feline\"\n",
      "en: \"kittens\"\n",
      "en: \"cats\"\n",
      "en: \"doggie\"\n",
      "en: \"parrot\"\n",
      "----------\n",
      "fr: \"chien\"\n",
      "en: \"dog\"\n",
      "en: \"cat\"\n",
      "en: \"pet\"\n",
      "en: \"pup\"\n",
      "en: \"doggie\"\n",
      "en: \"puppy\"\n",
      "en: \"canine\"\n",
      "en: \"bulldog\"\n",
      "en: \"kitten\"\n",
      "en: \"dogs\"\n",
      "----------\n",
      "fr: \"voiture\"\n",
      "en: \"car\"\n",
      "en: \"vehicle\"\n",
      "en: \"automobile\"\n",
      "en: \"motorbike\"\n",
      "en: \"motorcycle\"\n",
      "en: \"scooter\"\n",
      "en: \"cars\"\n",
      "en: \"taxi\"\n",
      "en: \"truck\"\n",
      "en: \"jeep\"\n",
      "----------\n",
      "fr: \"zut\"\n",
      "en: \"oops\"\n",
      "en: \"Ah\"\n",
      "en: \"ah\"\n",
      "en: \"nope\"\n",
      "en: \"hmm\"\n",
      "en: \"yep\"\n",
      "en: \"hmmm\"\n",
      "en: \"yup\"\n",
      "en: \"oh\"\n",
      "en: \"Oh\"\n"
     ]
    }
   ],
   "source": [
    "fr_word2vec = Word2Vec(fr_embeddings_path, vocab_size=50000)\n",
    "en_word2vec = Word2Vec(en_embeddings_path, vocab_size=50000)\n",
    "multilingual_word_aligner = MultilingualWordAligner(fr_word2vec, en_word2vec)\n",
    "\n",
    "# You will be evaluated on the output of the following:\n",
    "fr_words = ['finance', 'mission', 'attention', 'chat', 'chien', 'voiture', 'zut']\n",
    "k = 10\n",
    "for fr_word in fr_words:\n",
    "    print('-' * 10)\n",
    "    print(f'fr: \"{fr_word}\"')\n",
    "    en_words = multilingual_word_aligner.get_closest_english_words(fr_word, k)\n",
    "    for en_word in en_words:\n",
    "        print(f'en: \"{en_word}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to dive deeper on this subject: https://github.com/facebookresearch/MUSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Sentence classification with BoV and scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Load train/dev/test of Stanford Sentiment TreeBank (SST)\n",
    "#     (https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf)\n",
    "train_filepath = PATH_TO_DATA / 'SST/stsa.fine.train'\n",
    "dev_filepath = PATH_TO_DATA / 'SST/stsa.fine.dev'\n",
    "test_filepath = PATH_TO_DATA / 'SST/stsa.fine.test.X'\n",
    "\n",
    "# Load training sentences\n",
    "train_sentences = []\n",
    "train_labels = []\n",
    "with open(train_filepath, 'r') as f:\n",
    "    for line in f:\n",
    "        data = line.strip('\\n')\n",
    "        train_labels.append(data[0])\n",
    "        train_sentences.append(data[2:])\n",
    "        \n",
    "# Load dev sentences\n",
    "dev_sentences = []\n",
    "dev_labels = []\n",
    "with open(dev_filepath, 'r') as f:\n",
    "    for line in f:\n",
    "        data = line.strip('\\n')\n",
    "        dev_labels.append(data[0])\n",
    "        dev_sentences.append(data[2:])\n",
    "        \n",
    "# Load test sentences\n",
    "test_sentences = []\n",
    "test_labels = []\n",
    "with open(test_filepath, 'r') as f:\n",
    "    for line in f:\n",
    "        data = line.strip('\\n')\n",
    "        test_sentences.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50000 pretrained word vectors\n"
     ]
    }
   ],
   "source": [
    "# 2 - Encode sentences with the BoV model above\n",
    "word2vec = Word2Vec(en_embeddings_path, vocab_size=50000)\n",
    "sentence2vec = BagOfWords(word2vec)\n",
    "  \n",
    "train_labels, dev_labels = np.array(train_labels), np.array(dev_labels)\n",
    "train_sentences_embedding, dev_sentences_embedding, test_sentences_embedding = {}, {}, {}\n",
    "idf_techniques = {'idf':sentence2vec.build_idf(sentences), 'no_idf':None}\n",
    "for idf_name in idf_techniques.keys():\n",
    "\n",
    "    ### Training\n",
    "    train_embedding = []\n",
    "    for stc in train_sentences:\n",
    "        train_embedding.append(sentence2vec.encode(stc, idf_techniques[idf_name]))  # BagOfWords-idf\n",
    "\n",
    "    train_sentences_embedding[idf_name] = np.array(train_embedding)\n",
    "\n",
    "    ### Dev\n",
    "    dev_embedding = []\n",
    "    for stc in dev_sentences:\n",
    "        dev_embedding.append(sentence2vec.encode(stc, idf_techniques[idf_name]))  # BagOfWords-idf\n",
    "\n",
    "    dev_sentences_embedding[idf_name] = np.array(dev_embedding)\n",
    "\n",
    "    ### Test\n",
    "    test_embedding = []\n",
    "    for stc in test_sentences:\n",
    "        test_embedding.append(sentence2vec.encode(stc, idf_techniques[idf_name]))  # BagOfWords-idf\n",
    "\n",
    "    test_sentences_embedding[idf_name] = np.array(test_embedding)\n",
    "\n",
    "\n",
    "### Let's have a first glance at the labels distributions in each dataset\n",
    "\n",
    "#print('-'*50, 'Training Set')\n",
    "#for occ in np.unique(train_labels, return_counts=True)[1]:\n",
    "#    print(occ/len(train_labels))\n",
    "    \n",
    "#print('-'*50, 'Dev Set')\n",
    "#for occ in np.unique(dev_labels, return_counts=True)[1]:\n",
    "#    print(occ/len(dev_labels))\n",
    "\n",
    "# The distributions are very close to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------- idf\n",
      "---------------------------------------------------------------------- Training, Cross Validation\n",
      "[0.38807715 0.3886616  0.37039204 0.38781488 0.38921454]\n",
      "-> Mean training accuracy score :  0.3848\n",
      "---------------------------------------------------------------------- Validation\n",
      "Validation accuracy on the dev set :  0.3824\n",
      "\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------- no_idf\n",
      "---------------------------------------------------------------------- Training, Cross Validation\n",
      "[0.41729982 0.40736411 0.41310708 0.40480375 0.40152403]\n",
      "-> Mean training accuracy score :  0.4088\n",
      "---------------------------------------------------------------------- Validation\n",
      "Validation accuracy on the dev set :  0.4005\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3 - Learn Logistic Regression on top of sentence embeddings using scikit-learn\n",
    "#     (consider tuning the L2 regularization on the dev set)\n",
    "#     In the paper, the accuracy for average of word vectors is 32.7%\n",
    "#     (VecAvg, table 1, https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf)\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "log_reg = {}\n",
    "for idf_name in idf_techniques.keys():\n",
    "    print('-'*100, idf_name)\n",
    "    log_reg[idf_name] = RidgeClassifier(alpha=0.6, fit_intercept=True, max_iter=None, tol=0.001)\n",
    "    #transformer = PCA(0.95, whiten=True)\n",
    "    #pca_train_data = transformer.fit_transform(train_sentences_embedding[idf_name])\n",
    "    log_reg[idf_name].fit(train_sentences_embedding[idf_name], train_labels)\n",
    "    print('-'*70, 'Training, Cross Validation')\n",
    "    Accuracy = cross_val_score(log_reg[idf_name], train_sentences_embedding[idf_name], train_labels,\n",
    "                               cv=5,scoring='accuracy')\n",
    "    print(Accuracy)\n",
    "    print('-> Mean training accuracy score : ', round(np.mean(Accuracy), 4))\n",
    "\n",
    "    print('-'*70, 'Validation')\n",
    "    #pca_dev_data = transformer.transform(dev_sentences_embedding[idf_name])\n",
    "    dev_pred_labels = log_reg[idf_name].predict(dev_sentences_embedding[idf_name])\n",
    "    accuracy = accuracy_score(dev_labels, dev_pred_labels)\n",
    "    print('Validation accuracy on the dev set : ',round(accuracy,4))\n",
    "    print('\\n\\n')\n",
    "\n",
    "### Conclusion :\n",
    "# This approach yields better results without the IDF technique. \n",
    "# The results are pretty good with a validation accuracy of ~0.40 : can we perform better with other approaches ?\n",
    "# Interestingly, when we apply a PCA, the results with the idf technique are better than without \n",
    "# (but worse than when not using a PCA)\n",
    "\n",
    "# To go further : GRID SEARCH, ERROR ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 - Produce 2210 predictions for the test set (in the same order). One line = one prediction (=0,1,2,3,4).\n",
    "#     Attach the output file \"logreg_bov_y_test_sst.txt\" to your deliverable.\n",
    "#     You will be evaluated on the results of the test set.\n",
    "\n",
    "test_pred_labels = log_reg['no_idf'].predict(test_sentences_embedding['no_idf'])\n",
    "with open(r'logreg_bov_y_test_sst.txt', 'w') as f:\n",
    "    f.write(\"\\n\".join(\" \".join(map(str, pred)) for pred in test_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------- idf\n",
      "---------------------------------------------------------------------- Training, Cross Validation\n",
      "[0.39567504 0.39216832 0.36863663 0.3983597  0.39097304]\n",
      "-> Mean training accuracy score :  0.3892\n",
      "---------------------------------------------------------------------- Validation\n",
      "Validation accuracy on the dev set :  0.3833\n",
      "\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------- no_idf\n",
      "---------------------------------------------------------------------- Training, Cross Validation\n",
      "[0.42606663 0.41613092 0.42480983 0.40656122 0.4003517 ]\n",
      "-> Mean training accuracy score :  0.4148\n",
      "---------------------------------------------------------------------- Validation\n",
      "Validation accuracy on the dev set :  0.4069\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BONUS!\n",
    "# 5 - Try to improve performance with another classifier\n",
    "#     Attach the output file \"XXX_bov_y_test_sst.txt\" to your deliverable (where XXX = the name of the classifier)\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score#roc_auc_score\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "#ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3, min_samples_leaf=5),\n",
    "#                                   n_estimators=100,algorithm=\"SAMME.R\", learning_rate=0.2)\n",
    "### Adaboost is difficult to master and doesn't improve the results here...\n",
    "#rdf_clf = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "### Random Forest leads to 36% accuracy which is not great...\n",
    "\n",
    "clf = {}\n",
    "for idf_name in idf_techniques.keys():\n",
    "    print('-'*100, idf_name)\n",
    "    clf[idf_name] = LinearSVC(C=0.6, penalty='l2', dual=False)\n",
    "    #transformer = PCA(0.95, whiten=True)\n",
    "    #pca_train_data = transformer.fit_transform(train_sentences_embedding[idf_name])\n",
    "    clf[idf_name].fit(train_sentences_embedding[idf_name], train_labels)\n",
    "    print('-'*70, 'Training, Cross Validation')\n",
    "    Accuracy = cross_val_score(clf[idf_name], train_sentences_embedding[idf_name], train_labels,\n",
    "                               cv=5,scoring='accuracy')\n",
    "    print(Accuracy)\n",
    "    print('-> Mean training accuracy score : ', round(np.mean(Accuracy), 4))\n",
    "\n",
    "    print('-'*70, 'Validation')\n",
    "    #pca_dev_data = transformer.transform(dev_sentences_embedding[idf_name])\n",
    "    dev_pred_labels = clf[idf_name].predict(dev_sentences_embedding[idf_name])\n",
    "    accuracy = accuracy_score(dev_labels, dev_pred_labels)\n",
    "    print('Validation accuracy on the dev set : ',round(accuracy,4))\n",
    "    print('\\n\\n')\n",
    "\n",
    "### Conclusion : \n",
    "# Using an SVM improves a little bit (~+1%) but it doesn't improve that much. \n",
    "# Probably that the approach isn't the best one and might be improved. Using a grid search might yield a tiny bit\n",
    "# better results but nothing impressive. We will try to dig deeper in the approach instead.\n",
    "\n",
    "# To go further : GRID SEARCH and ERROR ANALYSIS\n",
    "test_pred_labels = clf['no_idf'].predict(test_sentences_embedding['no_idf'])\n",
    "with open(r'SVM_bov_y_test_sst.txt', 'w') as f:\n",
    "    f.write(\"\\n\".join(\" \".join(map(str, pred)) for pred in test_pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Sentence classification with LSTMs in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 - Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Using the same dataset, transform text to integers using tf.keras.preprocessing.text.one_hot function\n",
    "#     https://keras.io/preprocessing/text/\n",
    "\n",
    "text = ''\n",
    "for stc in train_sentences:\n",
    "    text += stc + ' '\n",
    "one_hot_dimension = len(set(tf.keras.preprocessing.text.text_to_word_sequence(text)))\n",
    "one_hot_dimension = round(one_hot_dimension)#*1.3) # Hashing trick might collide words\n",
    "encoding = tf.keras.preprocessing.text.one_hot(text, one_hot_dimension)\n",
    "\n",
    "### Create the training set\n",
    "train_encoded_data = []\n",
    "old_nb_words = 0\n",
    "for stc in train_sentences:\n",
    "    nb_words = len(tf.keras.preprocessing.text.text_to_word_sequence(stc))\n",
    "    train_encoded_data.append(encoding[old_nb_words:old_nb_words+nb_words])\n",
    "    old_nb_words += nb_words\n",
    "    \n",
    "### Create the dev and test sets\n",
    "# First, create a mapping of the words to their encoded value\n",
    "mapping = {}\n",
    "for wrd_idx, word in enumerate(tf.keras.preprocessing.text.text_to_word_sequence(text)):\n",
    "    mapping[word] = encoding[wrd_idx]\n",
    "\n",
    "# Dev set\n",
    "dev_encoded_data = []\n",
    "for stc in dev_sentences:\n",
    "    stc_encoding = []\n",
    "    for word in tf.keras.preprocessing.text.text_to_word_sequence(stc):\n",
    "        try:\n",
    "            stc_encoding.append(mapping[word])\n",
    "        except:\n",
    "            pass # then the word has never been seen before and thus is not in 'mapping'\n",
    "    dev_encoded_data.append(stc_encoding)\n",
    "    \n",
    "# Test set\n",
    "test_encoded_data = []\n",
    "for stc in test_sentences:\n",
    "    stc_encoding = []\n",
    "    for word in tf.keras.preprocessing.text.text_to_word_sequence(stc):\n",
    "        try:\n",
    "            stc_encoding.append(mapping[word])\n",
    "        except:\n",
    "            pass # then the word has never been seen before and thus is not in 'mapping'\n",
    "    test_encoded_data.append(stc_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Padding input data**\n",
    "\n",
    "Models in Keras (and elsewhere) take batches of sentences of the same length as input. It is because Deep Learning framework have been designed to handle well Tensors, which are particularly suited for fast computation on the GPU.\n",
    "\n",
    "Since sentences have different sizes, we \"pad\" them. That is, we add dummy \"padding\" tokens so that they all have the same length.\n",
    "\n",
    "The input to a Keras model thus has this size : (batchsize, maxseqlen) where maxseqlen is the maximum length of a sentence in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Pad your sequences using tf.keras.preprocessing.sequence.pad_sequences\n",
    "#     https://keras.io/preprocessing/sequence/\n",
    "\n",
    "# padding='pre' or 'post', whether to add zeros at the beginning or at the end of the sequence\n",
    "# First, get the maximal length on the total dataset to padd equally all of them\n",
    "max_length = 0\n",
    "for stc_encoded in train_encoded_data+dev_encoded_data+test_encoded_data:\n",
    "    stc_length = len(stc_encoded)\n",
    "    if stc_length > max_length:\n",
    "        max_length = stc_length\n",
    "        \n",
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(train_encoded_data, maxlen=max_length)\n",
    "x_dev = tf.keras.preprocessing.sequence.pad_sequences(dev_encoded_data, maxlen=max_length)\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(test_encoded_data, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 - Design and train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - Design your encoder + classifier using tensorflow.keras.layers\n",
    "#     In Keras, Torch and other deep learning framework, we create a \"container\" which is the Sequential() module.\n",
    "#     Then we add components to this container : the lookup-table, the LSTM, the classifier etc.\n",
    "#     All of these components are contained in the Sequential() and are trained together.\n",
    "#     Note that the embedding layer is initialized randomly and does not take advantage of pre-trained word embeddings.\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Activation\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.core.protobuf import rewriter_config_pb2\n",
    "\n",
    "#config_proto = K.ConfigProto()\n",
    "#off = rewriter_config_pb2.RewriterConfig.OFF\n",
    "#config_proto.graph_options.rewrite_options.arithmetic_optimization = off\n",
    "#session = K.Session(config=config_proto)\n",
    "#K.set_session(session)\n",
    "\n",
    "embed_dim  = 100  # word embedding dimension, previous value : 32\n",
    "nhid       = 256  # number of hidden units in the LSTM, previous value : 64\n",
    "vocab_size = 50000  # size of the vocabulary\n",
    "n_classes  = 5\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embed_dim)) # to adapt using our embedding\n",
    "model.add(LSTM(nhid, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "### Remark : \n",
    "# Using an embedding of 32 dimensions seems to low to allow the network to learn anything since the size \n",
    "# of the vocabulary is really huge. Indeed it might have to few degrees of freedom to represent the words and thus\n",
    "# the model doesn't perform well at all !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 100)         5000000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 256)               365568    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 5,366,853\n",
      "Trainable params: 5,366,853\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 4 - Define your loss/optimizer/metrics\n",
    "\n",
    "### After a few trainings we see that the model needs a high learning rate to overcome some local maxima at first\n",
    "# but then it doesn't fit properly. Thus we implement a learning rate scheduler to decrease the learning rate\n",
    "# value after a few epochs.\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "def schedule(epoch_idx, current_lr):\n",
    "    lr = current_lr\n",
    "    if epoch_idx%3==2:\n",
    "        lr *= 0.1\n",
    "    return lr\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(schedule)\n",
    "\n",
    "loss_classif     =  'categorical_crossentropy'\n",
    "# find the right loss for multi-class classification\n",
    "optimizer        =  tf.keras.optimizers.Adam(learning_rate=0.0005, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "# find the right optimizer\n",
    "metrics_classif  =  ['accuracy']\n",
    "\n",
    "# Observe how easy (but blackboxed) this is in Keras\n",
    "model.compile(loss=loss_classif,\n",
    "              optimizer=optimizer,\n",
    "              metrics=metrics_classif)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8544 samples, validate on 1101 samples\n",
      "Epoch 1/20\n",
      "8544/8544 [==============================] - 93s 11ms/sample - loss: 1.5687 - accuracy: 0.2815 - val_loss: 1.5590 - val_accuracy: 0.3361\n",
      "Epoch 2/20\n",
      "8544/8544 [==============================] - 95s 11ms/sample - loss: 1.4558 - accuracy: 0.3724 - val_loss: 1.3999 - val_accuracy: 0.3942\n",
      "Epoch 3/20\n",
      "8544/8544 [==============================] - 90s 11ms/sample - loss: 1.2069 - accuracy: 0.4963 - val_loss: 1.3760 - val_accuracy: 0.4087\n",
      "Epoch 4/20\n",
      "8544/8544 [==============================] - 94s 11ms/sample - loss: 1.1548 - accuracy: 0.5235 - val_loss: 1.3817 - val_accuracy: 0.4078\n",
      "Epoch 5/20\n",
      "8544/8544 [==============================] - 103s 12ms/sample - loss: 1.1193 - accuracy: 0.5442 - val_loss: 1.3772 - val_accuracy: 0.3969\n",
      "Epoch 6/20\n",
      "8544/8544 [==============================] - 96s 11ms/sample - loss: 1.0956 - accuracy: 0.5595 - val_loss: 1.3780 - val_accuracy: 0.3915\n",
      "Epoch 7/20\n",
      "8544/8544 [==============================] - 93s 11ms/sample - loss: 1.0854 - accuracy: 0.5585 - val_loss: 1.3805 - val_accuracy: 0.3942\n",
      "Epoch 8/20\n",
      "8544/8544 [==============================] - 97s 11ms/sample - loss: 1.0827 - accuracy: 0.5600 - val_loss: 1.3794 - val_accuracy: 0.3960\n",
      "Epoch 9/20\n",
      "8544/8544 [==============================] - 106s 12ms/sample - loss: 1.0815 - accuracy: 0.5606 - val_loss: 1.3796 - val_accuracy: 0.3951\n",
      "Epoch 10/20\n",
      "8544/8544 [==============================] - 96s 11ms/sample - loss: 1.0774 - accuracy: 0.5626 - val_loss: 1.3798 - val_accuracy: 0.3951\n",
      "Epoch 11/20\n",
      "8544/8544 [==============================] - 87s 10ms/sample - loss: 1.0824 - accuracy: 0.5562 - val_loss: 1.3796 - val_accuracy: 0.3951\n",
      "Epoch 12/20\n",
      "8544/8544 [==============================] - 87s 10ms/sample - loss: 1.0807 - accuracy: 0.5624 - val_loss: 1.3797 - val_accuracy: 0.3951\n",
      "Epoch 13/20\n",
      "8544/8544 [==============================] - 88s 10ms/sample - loss: 1.0818 - accuracy: 0.5641 - val_loss: 1.3797 - val_accuracy: 0.3951\n",
      "Epoch 14/20\n",
      "8544/8544 [==============================] - 90s 11ms/sample - loss: 1.0778 - accuracy: 0.5598 - val_loss: 1.3797 - val_accuracy: 0.3951\n",
      "Epoch 15/20\n",
      "8544/8544 [==============================] - 87s 10ms/sample - loss: 1.0820 - accuracy: 0.5631 - val_loss: 1.3797 - val_accuracy: 0.3951\n",
      "Epoch 16/20\n",
      "8544/8544 [==============================] - 88s 10ms/sample - loss: 1.0803 - accuracy: 0.5610 - val_loss: 1.3797 - val_accuracy: 0.3951\n",
      "Epoch 17/20\n",
      "8544/8544 [==============================] - 88s 10ms/sample - loss: 1.0805 - accuracy: 0.5618 - val_loss: 1.3797 - val_accuracy: 0.3951\n",
      "Epoch 18/20\n",
      "8544/8544 [==============================] - 89s 10ms/sample - loss: 1.0801 - accuracy: 0.5583 - val_loss: 1.3797 - val_accuracy: 0.3951\n",
      "Epoch 19/20\n",
      "8544/8544 [==============================] - 92s 11ms/sample - loss: 1.0791 - accuracy: 0.5640 - val_loss: 1.3797 - val_accuracy: 0.3951\n",
      "Epoch 20/20\n",
      "8544/8544 [==============================] - 93s 11ms/sample - loss: 1.0831 - accuracy: 0.5692 - val_loss: 1.3797 - val_accuracy: 0.3951\n",
      "Validation accuracy of our best model :  0.4087193460490463\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5 - Train your model and find the best hyperparameters for your dev set\n",
    "#     you will be evaluated on the quality of your predictions on the test set\n",
    "#     Keras expects y_train and y_dev to be one-hot encodings of the labels, i.e. with shape=(n_samples, 5)\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "#best_model_saver = ModelCheckpoint(filepath='./best_weights.hdf5', monitor=\"val_acc\", mode='max', verbose=1,\n",
    "#                                   save_best_only=True, save_weights_only=False)\n",
    "\n",
    "best_model_saver = ModelCheckpoint(filepath='./best_weights.hdf5', monitor='val_loss',\n",
    "                                   save_best_only=True, save_weights_only=False, mode='min', period=1)\n",
    "#early_stopper = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=2, mode='min',\n",
    "#                              baseline=None, restore_best_weights=False)\n",
    "\n",
    "\n",
    "### Training set\n",
    "# From labels to one-hot vectors\n",
    "int_train_labels = train_labels.astype('int')\n",
    "y_train = np.zeros((int_train_labels.shape[0], n_classes))\n",
    "for index, value in enumerate(int_train_labels):\n",
    "    y_train[index,value] = 1\n",
    "y_train = y_train.astype(int)\n",
    "    \n",
    "### Dev set\n",
    "# From labels to one-hot vectors\n",
    "int_dev_labels = dev_labels.astype('int')\n",
    "y_dev = np.zeros((int_dev_labels.shape[0], n_classes))\n",
    "for index, value in enumerate(int_dev_labels):\n",
    "    y_dev[index,value] = 1\n",
    "y_dev = y_dev.astype(int)\n",
    "\n",
    "bs = 64\n",
    "n_epochs = 20\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=bs, epochs=n_epochs, validation_data=(x_dev, y_dev),\n",
    "                    callbacks=[best_model_saver, lr_scheduler])#, early_stopper])\n",
    "\n",
    "model = load_model('best_weights.hdf5')\n",
    "predictions_one_hot = model.predict(x_dev)\n",
    "predictions = np.zeros(predictions_one_hot.shape, dtype=int)\n",
    "for idx in range(len(predictions_one_hot)):\n",
    "    predictions[idx][np.argmax(predictions_one_hot[idx])] = 1\n",
    "\n",
    "print('Validation accuracy of our best model : ', accuracy_score(y_dev, predictions))\n",
    "\n",
    "\n",
    "### Let's plot the training curves\n",
    "plt.figure(figsize=(18,6))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Improvements : \n",
    "#   - Grid Search of parameters\n",
    "#   - Attention mechanism ? (Transformers)\n",
    "#   - Better Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 - Generate your predictions on the test set using model.predict(x_test)\n",
    "#     https://keras.io/models/model/\n",
    "#     Log your predictions in a file (one line = one integer: 0,1,2,3,4)\n",
    "#     Attach the output file \"logreg_lstm_y_test_sst.txt\" to your deliverable.\n",
    "model = load_model('weights.best.hdf5')\n",
    "predictions_one_hot = model.predict(x_test)\n",
    "predictions = [np.argmax(pred) for pred in predictions_one_hot]\n",
    "\n",
    "def write_submission(path_output, predictions):\n",
    "    #function that writes the submission\n",
    "    lines = '\\n'.join([str(p) for p in predictions])\n",
    "    with open(path_output,'w') as f:\n",
    "        f.writelines(lines)\n",
    "\n",
    "    \n",
    "write_submission(os.path.join('.',r'logreg_lstm_y_test_sst.txt'), predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 - innovate !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15175 pretrained word vectors\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 49)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 49, 300)      4601400     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 49, 300)      4601400     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 49, 600)      0           embedding[0][0]                  \n",
      "                                                                 embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 49, 256)      153856      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention (MultiHead (None, 49, 256)      4217096     concatenate[0][0]                \n",
      "                                                                 concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 49, 256)      0           dense[0][0]                      \n",
      "                                                                 multi_head_attention[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 49, 256)      512         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 49, 256)      65792       multi_head_attention[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 49, 256)      0           layer_normalization[0][0]        \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 49, 256)      512         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 49, 256)      0           layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 46, 64)       65600       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 15, 64)       0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 15, 64)       0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 12, 64)       16448       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 4, 64)        0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 64)           0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64)           256         global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          33280       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512)          2048        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 512)          262656      batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 512)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 5)            2565        dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 14,023,421\n",
      "Trainable params: 9,420,869\n",
      "Non-trainable params: 4,602,552\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 7 - Open question: find a model that is better on your dev set\n",
    "#     (e.g: use a 1D ConvNet, use a better classifier, pretrain your lookup tables ..)\n",
    "#     you will get point if the results on the test set are better: be careful of not overfitting your dev set too much..\n",
    "#     Attach the output file \"XXX_XXX_y_test_sst.txt\" to your deliverable.\n",
    "\n",
    "from tensorflow.keras.layers import Layer, Dense, Attention, LayerNormalization, Concatenate, Add, \\\n",
    "                                    Dropout, Conv1D, MaxPool1D, GlobalAveragePooling1D, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    def __init__(self, fc_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.fc_dim = fc_dim\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.query_fc = Dense(self.fc_dim, activation=\"linear\")\n",
    "        self.value_fc = Dense(self.fc_dim, activation=\"linear\")\n",
    "        self.key_fc = Dense(self.fc_dim, activation=\"linear\")\n",
    "\n",
    "        self.att = Attention(use_scale=True)\n",
    "        super().build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        assert isinstance(inputs, list)\n",
    "        query = inputs[0]\n",
    "        value = inputs[1]\n",
    "        if len(inputs) > 2 and inputs[2] is not None:\n",
    "            key = inputs[2]\n",
    "        else:\n",
    "            key = value\n",
    "\n",
    "        query = self.query_fc(query)\n",
    "        value = self.value_fc(value)\n",
    "        key = self.key_fc(key)\n",
    "\n",
    "        return self.att([query, value, key])\n",
    "\n",
    "\n",
    "class MultiHeadAttention(Layer):\n",
    "    def __init__(self, n_heads, att_fc_dim, out_fc_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.n_heads = n_heads\n",
    "        self.att_fc_dim = att_fc_dim\n",
    "        self.out_fc_dim = out_fc_dim\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        query_shape = input_shape[0]\n",
    "        # Attention heads\n",
    "        for head in range(self.n_heads):\n",
    "            setattr(self, \"att_head_{}\".format(head), \n",
    "                    AttentionLayer(fc_dim=self.att_fc_dim))\n",
    "        \n",
    "        self.out_fc = Dense(self.out_fc_dim, activation=\"linear\")\n",
    "        self.layer_norm1 = LayerNormalization()\n",
    "        self.concat = Concatenate(axis=-1)        \n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        assert isinstance(inputs, list)\n",
    "        query = inputs[0]\n",
    "        value = inputs[1]\n",
    "        if len(inputs) > 2 and inputs[2] is not None:\n",
    "            key = inputs[2]\n",
    "        else:\n",
    "            key = value\n",
    "        \n",
    "        heads = []\n",
    "        for num_head in range(self.n_heads):\n",
    "            attention_head = getattr(self, \"att_head_{}\".format(num_head))\n",
    "            heads.append(attention_head([query, value, key]))\n",
    "        h = self.concat(heads)\n",
    "        return self.out_fc(h)\n",
    "\n",
    "\n",
    "### Architecture params\n",
    "# Embeddings\n",
    "max_len = 49\n",
    "learned_embedding_dim = 300\n",
    "embedding_dim = 300\n",
    "vocab_size = 50000\n",
    "\n",
    "# Prepare data\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(train_sentences)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "\n",
    "X_train = pad_sequences(t.texts_to_sequences(train_sentences), maxlen=max_len, padding='post')\n",
    "X_test = pad_sequences(t.texts_to_sequences(test_sentences), maxlen=max_len, padding='post')\n",
    "X_dev = pad_sequences(t.texts_to_sequences(dev_sentences), maxlen=max_len, padding='post')\n",
    "# if needed you can download the weights on the following website : https://nlp.stanford.edu/projects/glove/\n",
    "embeddings_path = \"./data/glove.42B.{}d.txt\".format(embedding_dim)\n",
    "embeddings_index = dict()\n",
    "with open(embeddings_path, 'rt', encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        word, vec = line.split(' ', 1)\n",
    "        if word in t.word_index:\n",
    "            embeddings_index[word] = np.fromstring(vec, sep=' ')\n",
    "print('Loaded %s pretrained word vectors' % (len(embeddings_index)))\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# Attention\n",
    "att_fc_dim = 256\n",
    "out_fc_dim = 256\n",
    "heads = 8\n",
    "\n",
    "# Convolutions\n",
    "n_filters = 64\n",
    "kernel_size = 4\n",
    "pool_size = 3\n",
    "\n",
    "# LSTM\n",
    "lstm_dim = 256\n",
    "\n",
    "# MLP & classifier\n",
    "n_classes  = 5\n",
    "dense_width = 512\n",
    "\n",
    "### Forward pass\n",
    "sentence = Input(shape=(max_len,))\n",
    "\n",
    "### Embeddings\n",
    "glove = Embedding(vocab_size, embedding_dim, weights=[embedding_matrix],\n",
    "                  input_length=max_len, trainable=False)(sentence)\n",
    "learned = Embedding(vocab_size, learned_embedding_dim, input_length=max_len)(sentence)\n",
    "x = Concatenate(axis=-1)([glove, learned])\n",
    "\n",
    "### Transformer Encoder 1\n",
    "x_ = MultiHeadAttention(n_heads=heads, att_fc_dim=att_fc_dim, \n",
    "                       out_fc_dim=out_fc_dim)([x, x])\n",
    "x = Dense(out_fc_dim, activation=\"relu\")(x)\n",
    "x = Add()([x, x_])\n",
    "x = LayerNormalization()(x)\n",
    "\n",
    "x_ = Dense(out_fc_dim, activation=\"relu\")(x_)\n",
    "x = Add()([x, x_])\n",
    "x = LayerNormalization()(x)\n",
    "\n",
    "### 1D Convolutions\n",
    "x = Dropout(0.25)(x)\n",
    "x = Conv1D(filters=n_filters, \n",
    "           kernel_size=kernel_size,\n",
    "           activation='relu',\n",
    "           padding='valid',\n",
    "           strides=1)(x)\n",
    "x = MaxPool1D(pool_size)(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Conv1D(filters=n_filters, \n",
    "           kernel_size=kernel_size,\n",
    "           activation='relu',\n",
    "           padding='valid',\n",
    "           strides=1)(x)\n",
    "x = MaxPool1D(pool_size)(x)\n",
    "\n",
    "### Pooling\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "\n",
    "### Classifier\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(dense_width, activation=\"relu\")(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(dense_width, activation=\"relu\")(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "out = Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=sentence, outputs=out)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 - Define your loss/optimizer/metrics\n",
    "\n",
    "### After a few trainings we see that the model needs a high learning rate to overcome some local maxima at first\n",
    "# but then it doesn't fit properly. Thus we implement a learning rate scheduler to decrease the learning rate\n",
    "# value after a few epochs.\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "def schedule(epoch_idx, current_lr, step=6, decay=0.5):\n",
    "    lr = current_lr\n",
    "    if epoch_idx%step==(step-1):\n",
    "        lr *= decay\n",
    "    return lr\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(schedule)\n",
    "\n",
    "loss_classif     =  'categorical_crossentropy'\n",
    "# find the right loss for multi-class classification\n",
    "optimizer        =  tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "# find the right optimizer\n",
    "metrics_classif  =  ['accuracy']\n",
    "\n",
    "# Observe how easy (but blackboxed) this is in Keras\n",
    "model.compile(loss=loss_classif,\n",
    "              optimizer=optimizer,\n",
    "              metrics=metrics_classif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Train on 8544 samples, validate on 1101 samples\n",
      "Epoch 1/20\n",
      "1664/8544 [====>.........................] - ETA: 4:58 - loss: 3.2000 - accuracy: 0.2163"
     ]
    }
   ],
   "source": [
    "# 5 - Train your model and find the best hyperparameters for your dev set\n",
    "#     you will be evaluated on the quality of your predictions on the test set\n",
    "#     Keras expects y_train and y_dev to be one-hot encodings of the labels, i.e. with shape=(n_samples, 5)\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "#best_model_saver = ModelCheckpoint(filepath='./best_weights.hdf5', monitor=\"val_acc\", mode='max', verbose=1,\n",
    "#                                   save_best_only=True, save_weights_only=False)\n",
    "\n",
    "best_model_saver = ModelCheckpoint(filepath='./transfo_best_weights.hdf5', monitor='val_loss',\n",
    "                                   save_best_only=True, save_weights_only=True, mode='min', period=1)\n",
    "#early_stopper = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=2, mode='min',\n",
    "#                              baseline=None, restore_best_weights=False)\n",
    "\n",
    "\n",
    "### Training set\n",
    "# From labels to one-hot vectors\n",
    "int_train_labels = train_labels.astype('int')\n",
    "y_train = np.zeros((int_train_labels.shape[0], n_classes))\n",
    "for index, value in enumerate(int_train_labels):\n",
    "    y_train[index,value] = 1\n",
    "y_train = y_train.astype(int)\n",
    "    \n",
    "### Dev set\n",
    "# From labels to one-hot vectors\n",
    "int_dev_labels = dev_labels.astype('int')\n",
    "y_dev = np.zeros((int_dev_labels.shape[0], n_classes))\n",
    "for index, value in enumerate(int_dev_labels):\n",
    "    y_dev[index,value] = 1\n",
    "y_dev = y_dev.astype(int)\n",
    "\n",
    "bs = 64\n",
    "n_epochs = 20\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=bs, epochs=n_epochs, validation_data=(x_dev, y_dev),\n",
    "                    callbacks=[lr_scheduler,best_model_saver])#, early_stopper])\n",
    "\n",
    "model.load_weights('transfo_best_weights.h5')\n",
    "predictions_one_hot = model.predict(x_dev)\n",
    "predictions = np.zeros(predictions_one_hot.shape, dtype=int)\n",
    "for idx in range(len(predictions_one_hot)):\n",
    "    predictions[idx][np.argmax(predictions_one_hot[idx])] = 1\n",
    "\n",
    "print('Validation accuracy of our best model : ', accuracy_score(y_dev, predictions))\n",
    "\n",
    "\n",
    "### Let's plot the training curves\n",
    "plt.figure(figsize=(18,6))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Improvements : \n",
    "#   - Grid Search of parameters\n",
    "#   - Better Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
